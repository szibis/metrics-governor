# Testing limits configuration - calibrated to trigger against generator output
#
# This configuration is designed for integration testing of limits enforcement.
# The limits are set lower than actual generator cardinality to ensure violations
# are triggered and enforcement behavior can be verified.
#
# Usage:
#   docker compose -f docker-compose.yaml -f compose_overrides/limits.yaml up -d --build
#
# Actions:
#   - log:      Log violation but pass through data (default)
#   - adaptive: Intelligently drop top offenders to stay within limits
#   - drop:     Drop all data when limit exceeded
#
# Spike scenarios (when ENABLE_SPIKE_SCENARIOS=true):
#   - Random spikes: Create 1000 series over 20s, spike_* metrics
#   - Mistake scenario: Create 100 new series/sec for 2min, mistake_* metrics
#   Both use separate MeterProviders that are shutdown after the event,
#   allowing clean recovery testing.

defaults:
  max_datapoints_rate: 50000     # per minute - moderate default
  max_cardinality: 1000          # Low default to catch unexpected cardinality
  action: log

rules:
  # HTTP request metrics - normal traffic produces ~1,200 series
  # Limit set at 800 to ensure violations
  - name: "http-metrics-limit"
    match:
      metric_name: "http_request.*"
    max_cardinality: 800
    max_datapoints_rate: 5000    # per minute
    action: adaptive
    group_by: ["service", "env", "endpoint"]

  # High cardinality metric - stabilizes at ~2,500 series
  # Limit at 1,500 to trigger adaptive limiting
  - name: "high-card-metric-limit"
    match:
      metric_name: "high_cardinality_metric"
    max_cardinality: 1500
    action: adaptive
    group_by: ["service", "region", "instance"]

  # User events - grows ~3,000 series/min
  # Limit at 2,000 to trigger enforcement
  - name: "user-events-limit"
    match:
      metric_name: "high_card_user_events"
    max_cardinality: 2000
    action: adaptive
    group_by: ["service", "event_type"]

  # API requests - grows ~2,000 series/min
  # Limit at 1,500 to trigger enforcement
  - name: "api-requests-limit"
    match:
      metric_name: "high_card_api_requests"
    max_cardinality: 1500
    action: adaptive
    group_by: ["service", "path"]

  # DB queries - exceeds quickly
  - name: "db-queries-limit"
    match:
      metric_name: "high_card_db_queries"
    max_cardinality: 500
    action: adaptive
    group_by: ["service", "database", "operation"]

  # Cache operations - exceeds quickly
  - name: "cache-ops-limit"
    match:
      metric_name: "high_card_cache_operations"
    max_cardinality: 500
    action: adaptive
    group_by: ["service", "operation"]

  # Spike metric - hard drop when spike creates 1,000 series
  # Limit at 200 ensures immediate enforcement
  - name: "spike-metric-limit"
    match:
      metric_name: "spike_.*"
    max_cardinality: 200
    action: drop

  # Mistake metric - adaptive limiting when bad deployment floods
  # Limit at 300 with rate limiting to catch the flood
  - name: "mistake-metric-limit"
    match:
      metric_name: "mistake_.*"
    max_cardinality: 300
    max_datapoints_rate: 2000    # per minute
    action: adaptive
    group_by: ["service", "env"]

  # Burst traffic - hard drop on cardinality explosion
  - name: "burst-traffic-limit"
    match:
      metric_name: "burst_traffic_metric"
    max_cardinality: 500
    action: drop

  # Legacy app metrics - exceeds due to high request_id cardinality
  - name: "legacy-app-limit"
    match:
      metric_name: "legacy_app_.*"
    max_cardinality: 500
    max_datapoints_rate: 3000    # per minute
    action: adaptive
    group_by: ["service", "env"]
